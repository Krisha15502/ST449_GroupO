{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cH4IPnGf6oku"
      },
      "source": [
        "# Arizona Gerrymandering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGX16MJarJty"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "as04zSufq-Fs"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random seed set to 449 for reproducibility\n"
          ]
        }
      ],
      "source": [
        "import geopandas as gpd\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from shapely.geometry import Point\n",
        "from scipy.spatial import distance_matrix\n",
        "import networkx as nx\n",
        "from collections import deque\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "import heapq\n",
        "import time\n",
        "\n",
        "warnings.filterwarnings('ignore', category=FutureWarning)\n",
        "warnings.filterwarnings('ignore', category=UserWarning)\n",
        "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
        "\n",
        "# Set global random seed for reproducibility\n",
        "RANDOM_SEED = 111\n",
        "np.random.seed(RANDOM_SEED)\n",
        "random.seed(RANDOM_SEED)\n",
        "print(f\"Random seed set to {RANDOM_SEED} for reproducibility\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ“ Matplotlib styled with Times New Roman font and professional color palette\n"
          ]
        }
      ],
      "source": [
        "# Set Times New Roman as default font\n",
        "plt.rcParams['font.family'] = 'serif'\n",
        "plt.rcParams['font.serif'] = ['Times New Roman']\n",
        "plt.rcParams['font.size'] = 10\n",
        "plt.rcParams['axes.labelsize'] = 11\n",
        "plt.rcParams['axes.titlesize'] = 12\n",
        "plt.rcParams['xtick.labelsize'] = 9\n",
        "plt.rcParams['ytick.labelsize'] = 9\n",
        "plt.rcParams['legend.fontsize'] = 10\n",
        "\n",
        "# Professional Academic Color Palette\n",
        "COLORS = {\n",
        "    'efficiency_gap': '#1f77b4',      # Navy Blue - primary metric\n",
        "    'compactness': '#2ca02c',         # Forest Green - quality metric\n",
        "    'democratic': '#3182bd',          # Blue - Democratic party\n",
        "    'republican': '#de2d26',          # Red - Republican party\n",
        "    'acceptance_rate': '#ff7f0e',     # Dark Orange - algorithm performance\n",
        "    'scatter': '#9467bd',             # Royal Purple - analysis\n",
        "    'neutral': '#7f7f7f',             # Gray - reference lines\n",
        "    'background': '#f0f0f0'           # Light gray - backgrounds\n",
        "}\n",
        "\n",
        "print(f\"âœ“ Matplotlib styled with Times New Roman font and professional color palette\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrkhoqphrOBL"
      },
      "source": [
        "### Graph Construction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "ftvrBRLOrFc8"
      },
      "outputs": [],
      "source": [
        "def build_adjacency_graph(gdf):\n",
        "    \"\"\"Builds adjacency graph from Voting Districts in the Shp.\"\"\"\n",
        "    G = nx.Graph()\n",
        "    for idx in gdf.index:\n",
        "        G.add_node(idx)\n",
        "\n",
        "    # Find neighbors using spatial intersection\n",
        "    for i, geom_i in enumerate(gdf.geometry):\n",
        "        for j in range(i + 1, len(gdf)):\n",
        "            geom_j = gdf.geometry.iloc[j]\n",
        "            if geom_i.touches(geom_j) or geom_i.intersects(geom_j):\n",
        "                G.add_edge(i, j)\n",
        "\n",
        "    return G"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_RBX3ljreUq"
      },
      "source": [
        "### Initialisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "T8xD9XcDrTI1"
      },
      "outputs": [],
      "source": [
        "def build_spanning_tree(vtd_indices, graph):\n",
        "    \"\"\"Build random spanning tree of given VTDs using Kruskal's algorithm.\"\"\"\n",
        "    # Subgraph of only these VTDs\n",
        "    subgraph = graph.subgraph(vtd_indices).copy()\n",
        "\n",
        "    # Get all edges and shuffle\n",
        "    edges = list(subgraph.edges())\n",
        "    random.shuffle(edges)\n",
        "\n",
        "    # Kruskal's algorithm with union-find\n",
        "    parent = {v: v for v in vtd_indices}\n",
        "\n",
        "    def find(v):\n",
        "        if parent[v] != v:\n",
        "            parent[v] = find(parent[v])\n",
        "        return parent[v]\n",
        "\n",
        "    def union(u, v):\n",
        "        root_u = find(u)\n",
        "        root_v = find(v)\n",
        "        if root_u != root_v:\n",
        "            parent[root_u] = root_v\n",
        "            return True\n",
        "        return False\n",
        "\n",
        "    tree_edges = []\n",
        "    for u, v in edges:\n",
        "        if union(u, v):\n",
        "            tree_edges.append((u, v))\n",
        "            if len(tree_edges) == len(vtd_indices) - 1:\n",
        "                break\n",
        "\n",
        "    return nx.Graph(tree_edges)\n",
        "\n",
        "\n",
        "def find_best_balanced_cut_multi_tree(gdf, graph, vtd_list, target_left_pop, region_pop, node_repeats=10):\n",
        "    \"\"\"\n",
        "    Try multiple spanning trees and find the best balanced cut.\n",
        "\n",
        "    Parameters:\n",
        "    - node_repeats: Number of random spanning trees to try\n",
        "\n",
        "    Returns: (best_left_vtds, best_right_vtds) or None\n",
        "    \"\"\"\n",
        "\n",
        "    best_cut = None\n",
        "    best_deviation = float('inf')\n",
        "\n",
        "    for attempt in range(node_repeats):\n",
        "        # Build a random spanning tree\n",
        "        tree = build_spanning_tree(vtd_list, graph)\n",
        "\n",
        "        if tree.number_of_nodes() == 0:\n",
        "            continue\n",
        "\n",
        "        # Try all edges in this tree\n",
        "        for edge in tree.edges():\n",
        "            tree_temp = tree.copy()\n",
        "            tree_temp.remove_edge(*edge)\n",
        "            components = list(nx.connected_components(tree_temp))\n",
        "\n",
        "            if len(components) != 2:\n",
        "                continue\n",
        "\n",
        "            pop1 = gdf.loc[list(components[0]), 'TOTAL'].sum()\n",
        "            pop2 = gdf.loc[list(components[1]), 'TOTAL'].sum()\n",
        "\n",
        "            # Calculate deviation from target\n",
        "            dev1 = abs(pop1 - target_left_pop) / target_left_pop if target_left_pop > 0 else float('inf')\n",
        "            dev2 = abs(pop2 - (region_pop - target_left_pop)) / (region_pop - target_left_pop) if (region_pop - target_left_pop) > 0 else float('inf')\n",
        "            max_dev = max(dev1, dev2)\n",
        "\n",
        "            if max_dev < best_deviation:\n",
        "                best_deviation = max_dev\n",
        "                best_cut = (list(components[0]), list(components[1]))\n",
        "\n",
        "    return best_cut\n",
        "\n",
        "\n",
        "def recursive_tree_part_init(gdf, graph, num_districts, ideal_pop, tolerance=0.05, node_repeats=10):\n",
        "    \"\"\"\n",
        "    Initialize districts using recursive tree partitioning with multiple tree attempts.\n",
        "    Guarantees contiguity and population balance.\n",
        "\n",
        "    Parameters:\n",
        "    - node_repeats: Number of spanning trees to try per split (higher = better balance, slower)\n",
        "    \"\"\"\n",
        "    print(f\"  Using recursive tree partitioning (node_repeats={node_repeats})...\")\n",
        "\n",
        "    def bisect_region(vtd_list, num_parts, depth=0):\n",
        "        \"\"\"Recursively split a region into num_parts districts.\"\"\"\n",
        "\n",
        "        if num_parts == 1:\n",
        "            # Base case: return all VTDs assigned to district 1 (1-indexed for this code)\n",
        "            return {vtd: 1 for vtd in vtd_list}\n",
        "\n",
        "        if len(vtd_list) < num_parts:\n",
        "            # Edge case: more districts than VTDs\n",
        "            result = {}\n",
        "            for i, vtd in enumerate(vtd_list):\n",
        "                result[vtd] = (i % num_parts) + 1  # 1-indexed\n",
        "            return result\n",
        "\n",
        "        # Calculate target populations\n",
        "        region_pop = gdf.loc[vtd_list, 'TOTAL'].sum()\n",
        "\n",
        "        # Split proportional to number of districts in each part\n",
        "        left_parts = num_parts // 2\n",
        "        right_parts = num_parts - left_parts\n",
        "\n",
        "        target_left_pop = region_pop * (left_parts / num_parts)\n",
        "\n",
        "        # Try multiple spanning trees to find best cut\n",
        "        best_cut = find_best_balanced_cut_multi_tree(\n",
        "            gdf, graph, vtd_list, target_left_pop, region_pop, node_repeats=node_repeats\n",
        "        )\n",
        "\n",
        "        if best_cut is None:\n",
        "            # Fallback: simple split\n",
        "            mid = len(vtd_list) // 2\n",
        "            best_cut = (vtd_list[:mid], vtd_list[mid:])\n",
        "\n",
        "        # Recursively split each half\n",
        "        left_assign = bisect_region(best_cut[0], left_parts, depth+1)\n",
        "        right_assign = bisect_region(best_cut[1], right_parts, depth+1)\n",
        "\n",
        "        # Offset right assignments by number of left districts\n",
        "        right_assign = {vtd: dist + left_parts for vtd, dist in right_assign.items()}\n",
        "\n",
        "        # Merge\n",
        "        return {**left_assign, **right_assign}\n",
        "\n",
        "    # Start recursion\n",
        "    all_vtds = list(gdf.index)\n",
        "    assignments = bisect_region(all_vtds, num_districts)\n",
        "\n",
        "    # Report\n",
        "    district_pops = {}\n",
        "    for i in range(1, num_districts + 1):  # 1-indexed\n",
        "        vtds_in_dist = [vtd for vtd, dist in assignments.items() if dist == i]\n",
        "        district_pops[i] = gdf.loc[vtds_in_dist, 'TOTAL'].sum()\n",
        "\n",
        "    print(\"  Initial district populations:\")\n",
        "    for i in range(1, num_districts + 1):\n",
        "        dev = abs(district_pops[i] - ideal_pop) / ideal_pop\n",
        "        print(f\"    District {i}: {district_pops[i]:>10,.0f} ({dev:>6.1%} deviation)\")\n",
        "\n",
        "    return pd.Series([assignments[idx] for idx in gdf.index], index=gdf.index)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zl0Dar9Org8I"
      },
      "source": [
        "### Constraint Calculations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "xx3AXPJkrxi2"
      },
      "outputs": [],
      "source": [
        "def is_district_contiguous(gdf, graph, district):\n",
        "    \"\"\"Check if a district forms a connected component using Breadth First Search (BFS).\"\"\"\n",
        "    vtds = gdf[gdf['district'] == district].index.tolist()\n",
        "\n",
        "    if len(vtds) == 0:\n",
        "        return True\n",
        "\n",
        "    # Breadth First Search to check connectivity\n",
        "    visited = set([vtds[0]])\n",
        "    queue = deque([vtds[0]])\n",
        "\n",
        "    while queue:\n",
        "        current = queue.popleft()\n",
        "        for neighbor in graph.neighbors(current):\n",
        "            if neighbor in vtds and neighbor not in visited:\n",
        "                visited.add(neighbor)\n",
        "                queue.append(neighbor)\n",
        "\n",
        "    return len(visited) == len(vtds)\n",
        "\n",
        "\n",
        "def polsby_popper_score(district_stats, district):\n",
        "    \"\"\"\n",
        "    Compute Polsby-Popper compactness score for a district.\n",
        "    Score = 4Ï€ * Area / PerimeterÂ²\n",
        "    Range: 0 to 1 (1 = perfect circle)\n",
        "    \"\"\"\n",
        "    area = district_stats[district]['area']\n",
        "    perimeter = district_stats[district]['perimeter']\n",
        "\n",
        "    if perimeter == 0:\n",
        "        return 0\n",
        "    return (4 * np.pi * area) / (perimeter ** 2)\n",
        "\n",
        "\n",
        "def wasted_votes(r_votes, d_votes):\n",
        "    \"\"\"\n",
        "    Calculate wasted vote ratio for a district based on party preference.\n",
        "    Wasted Votes:\n",
        "    - For winning party: Votes beyond 50% + 1\n",
        "    - For losing party: All votes\n",
        "    \"\"\"\n",
        "    total_votes = r_votes + d_votes\n",
        "    half_votes = total_votes // 2 + 1\n",
        "\n",
        "    if d_votes > r_votes:\n",
        "        wasted_d = d_votes - half_votes\n",
        "        wasted_r = r_votes\n",
        "    else:\n",
        "        wasted_d = d_votes\n",
        "        wasted_r = r_votes - half_votes\n",
        "    return wasted_d, wasted_r\n",
        "\n",
        "\n",
        "def district_stats_object(gdf, graph):\n",
        "    \"\"\"Create a district stats object to hold populations and other stats.\"\"\"\n",
        "    district_stats = {}\n",
        "    # Calculate stats for each district\n",
        "    for district_id in gdf['district'].unique():\n",
        "        district_data = gdf[gdf['district'] == district_id]\n",
        "        district_geom = district_data.unary_union\n",
        "\n",
        "        district_stats[district_id] = {\n",
        "            'contiguity': is_district_contiguous(gdf, graph, district_id),\n",
        "            'population': district_data['TOTAL'].sum(),\n",
        "            'area': district_geom.area,\n",
        "            'perimeter': district_geom.length,\n",
        "            'polsby_popper': (4 * np.pi * district_geom.area) / (district_geom.length ** 2) if district_geom.length > 0 else 0,\n",
        "            'VoterReg_D': district_data['VoterReg_D'].sum(),\n",
        "            'VoterReg_R': district_data['VoterReg_R'].sum(),\n",
        "            'wasted_D_votes': wasted_votes(district_data['VoterReg_R'].sum(), district_data['VoterReg_D'].sum())[0],\n",
        "            'wasted_R_votes': wasted_votes(district_data['VoterReg_R'].sum(), district_data['VoterReg_D'].sum())[1],\n",
        "        }\n",
        "\n",
        "    return district_stats"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7HmWQ8KuoTu"
      },
      "source": [
        "### Constraints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "FVnk9KOQrxGy"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ------------- Constraint 1: Contiguity -------------\n",
        "\n",
        "def is_flip_contiguous(gdf, graph, vtd_id, old_district):\n",
        "    \"\"\"\n",
        "    Check if flipping a VTD maintains contiguity by verifying all neighbor VTDs\n",
        "    in old_district can still reach each other.\n",
        "    \"\"\"\n",
        "    # Get all neighbors of the flipped VTD in the old district\n",
        "    neighbors = list(graph.neighbors(vtd_id))\n",
        "    old_district_neighbors = [n for n in neighbors if gdf.loc[n, 'district'] == old_district]\n",
        "\n",
        "    if len(old_district_neighbors) == 0:\n",
        "        return True\n",
        "\n",
        "    if len(old_district_neighbors) == 1:\n",
        "        return True\n",
        "\n",
        "    # Check if all neighbors can reach the first neighbor\n",
        "    # (without going through the flipped VTD)\n",
        "    start = old_district_neighbors[0]\n",
        "    for target in old_district_neighbors[1:]:\n",
        "\n",
        "        # BFS from start to target, only through old_district VTDs (excluding vtd_id)\n",
        "        visited = {start}\n",
        "        queue = deque([start])\n",
        "        found = False\n",
        "\n",
        "        while queue and not found:\n",
        "            current = queue.popleft()\n",
        "\n",
        "            for neighbor in graph.neighbors(current):\n",
        "                if neighbor == vtd_id:\n",
        "                    continue  # Skip the flipped VTD\n",
        "                if gdf.loc[neighbor, 'district'] != old_district:\n",
        "                    continue  # Only traverse within old_district\n",
        "                if neighbor in visited:\n",
        "                    continue\n",
        "\n",
        "                if neighbor == target:\n",
        "                    found = True\n",
        "                    break\n",
        "\n",
        "                visited.add(neighbor)\n",
        "                queue.append(neighbor)\n",
        "\n",
        "        if not found:\n",
        "            return False\n",
        "\n",
        "    return True\n",
        "\n",
        "\n",
        "# ------------- Constraint 2: Population Balance -------------\n",
        "\n",
        "def calculate_pop_bounds(district_stats, pop_tolerance):\n",
        "    \"\"\"Calculate lower and upper population bounds based on ideal population and tolerance.\"\"\"\n",
        "    total_pop = sum(stats['population'] for stats in district_stats.values())\n",
        "    num_districts = len(district_stats)\n",
        "    ideal_pop = total_pop / num_districts\n",
        "    pop_lower_bound = (1 - pop_tolerance) * ideal_pop\n",
        "    pop_upper_bound = (1 + pop_tolerance) * ideal_pop\n",
        "    return pop_lower_bound, pop_upper_bound\n",
        "\n",
        "\n",
        "def are_all_districts_pops_balanced(district_pops, pop_lower_bound, pop_upper_bound):\n",
        "    \"\"\"Check if all districts are within population tolerance.\"\"\"\n",
        "    return all(pop_lower_bound <= pop <= pop_upper_bound for pop in district_pops.values())\n",
        "\n",
        "\n",
        "def is_flip_pop_balanced(district_pops, vtd_pop, old_district, new_district, pop_lower_bound, pop_upper_bound):\n",
        "    \"\"\"\n",
        "    Check if both affected districts would remain within population tolerance after flip.\n",
        "    \"\"\"\n",
        "    # Calculate what populations would be after flip\n",
        "    new_old_pop = district_pops[old_district] - vtd_pop\n",
        "    new_new_pop = district_pops[new_district] + vtd_pop\n",
        "\n",
        "    # Check if both districts stay within tolerance\n",
        "    old_balanced = pop_lower_bound <= new_old_pop <= pop_upper_bound\n",
        "    new_balanced = pop_lower_bound <= new_new_pop <= pop_upper_bound\n",
        "\n",
        "    return old_balanced and new_balanced\n",
        "\n",
        "\n",
        "# ------------- Constraint 3: Compactness -------------\n",
        "\n",
        "def calculate_compactness_bounds(district_stats, compactness_tolerance):\n",
        "    \"\"\"Calculate lower compactness bound based on ideal compactness and tolerance.\"\"\"\n",
        "    ideal_compactness = np.mean([stats['polsby_popper'] for stats in district_stats.values()])\n",
        "    compactness_lower_bound = (1 - compactness_tolerance) * ideal_compactness\n",
        "    return compactness_lower_bound\n",
        "\n",
        "\n",
        "def are_all_districts_compactness_balanced(district_stats, compactness_lower_bound):\n",
        "    \"\"\"Check if all districts are within compactness tolerance.\"\"\"\n",
        "    return all(stats['polsby_popper'] >= compactness_lower_bound for stats in district_stats.values())\n",
        "\n",
        "\n",
        "def is_flip_compactness_balanced(gdf, vtd_id, vtd_geom, old_district, new_district, compactness_lower_bound):\n",
        "    \"\"\"\n",
        "    Check if both affected districts remain within compactness tolerance after a flip.\n",
        "    \"\"\"\n",
        "\n",
        "    # Calculate OLD district's new geometry (removing vtd)\n",
        "    old_district_vtds = gdf[(gdf['district'] == old_district) & (gdf.index != vtd_id)]\n",
        "    if len(old_district_vtds) > 0:\n",
        "        old_district_new_geom = old_district_vtds.unary_union\n",
        "        old_area = old_district_new_geom.area\n",
        "        old_perimeter = old_district_new_geom.length\n",
        "\n",
        "        if old_perimeter > 0:\n",
        "            old_polsby_popper = (4 * np.pi * old_area) / (old_perimeter ** 2)\n",
        "        else:\n",
        "            old_polsby_popper = 0\n",
        "\n",
        "        if old_polsby_popper < compactness_lower_bound:\n",
        "            return False\n",
        "\n",
        "    # Calculate NEW district's new geometry (adding vtd)\n",
        "    new_district_vtds = gdf[(gdf['district'] == new_district) | (gdf.index == vtd_id)]\n",
        "    new_district_new_geom = new_district_vtds.unary_union\n",
        "    new_area = new_district_new_geom.area\n",
        "    new_perimeter = new_district_new_geom.length\n",
        "\n",
        "    if new_perimeter > 0:\n",
        "        new_polsby_popper = (4 * np.pi * new_area) / (new_perimeter ** 2)\n",
        "    else:\n",
        "        new_polsby_popper = 0\n",
        "\n",
        "    if new_polsby_popper < compactness_lower_bound:\n",
        "        return False\n",
        "\n",
        "    return True\n",
        "\n",
        "\n",
        "# ------------- Constraint 4: Vote Efficiency -------------\n",
        "\n",
        "def does_flip_improve_vote_efficiency(district_stats, vtd_r_votes, vtd_d_votes, old_district, new_district, party_preference=None):\n",
        "    \"\"\"\n",
        "    Check if flipping a VTD improves vote efficiency based on partisan preference.\n",
        "\n",
        "    Returns:\n",
        "    - True if flip improves efficiency for the preferred party\n",
        "    \"\"\"\n",
        "    # Current wasted votes\n",
        "    current_old_wasted_d = district_stats[old_district]['wasted_D_votes']\n",
        "    current_old_wasted_r = district_stats[old_district]['wasted_R_votes']\n",
        "    current_new_wasted_d = district_stats[new_district]['wasted_D_votes']\n",
        "    current_new_wasted_r = district_stats[new_district]['wasted_R_votes']\n",
        "\n",
        "    # New wasted votes after flip\n",
        "    flip_old_r_votes = district_stats[old_district]['VoterReg_R'] - vtd_r_votes\n",
        "    flip_old_d_votes = district_stats[old_district]['VoterReg_D'] - vtd_d_votes\n",
        "    flip_new_r_votes = district_stats[new_district]['VoterReg_R'] + vtd_r_votes\n",
        "    flip_new_d_votes = district_stats[new_district]['VoterReg_D'] + vtd_d_votes\n",
        "\n",
        "    flip_wasted_old_d, flip_wasted_old_r = wasted_votes(flip_old_r_votes, flip_old_d_votes)\n",
        "    flip_wasted_new_d, flip_wasted_new_r = wasted_votes(flip_new_r_votes, flip_new_d_votes)\n",
        "\n",
        "    # Calculate change in wasted votes (positive = more waste after flip)\n",
        "    change_wasted_d = (flip_wasted_old_d + flip_wasted_new_d) - (current_old_wasted_d + current_new_wasted_d)\n",
        "    change_wasted_r = (flip_wasted_old_r + flip_wasted_new_r) - (current_old_wasted_r + current_new_wasted_r)\n",
        "\n",
        "    if party_preference == 'D':\n",
        "        # Democrats improve if: R waste increases MORE than D waste increases\n",
        "        return change_wasted_r > change_wasted_d\n",
        "    elif party_preference == 'R':\n",
        "        # Republicans improve if: D waste increases MORE than R waste increases\n",
        "        return change_wasted_d > change_wasted_r\n",
        "    else:\n",
        "        # Neutral: total wasted votes should decrease\n",
        "        return (change_wasted_d + change_wasted_r) < 0\n",
        "\n",
        "\n",
        "# ------------- Combined Constraint Check with Rejection Tracking -------------\n",
        "\n",
        "def check_flip(gdf, graph, district_stats, vtd_id, vtd_geom, vtd_pop, vtd_r_votes, vtd_d_votes,\n",
        "               old_district, new_district, pop_lower_bound, pop_upper_bound,\n",
        "               compactness_lower_bound, party_preference=None):\n",
        "    \"\"\"\n",
        "    Check flip constraints and track which constraint fails (if any).\n",
        "\n",
        "    CHANGED: Now returns tuple (is_valid, rejection_reason)\n",
        "    \"\"\"\n",
        "    # Check contiguity\n",
        "    if not is_flip_contiguous(gdf, graph, vtd_id, old_district):\n",
        "        return False, 'contiguity'\n",
        "\n",
        "    # Check population balance\n",
        "    if not is_flip_pop_balanced(\n",
        "        {d: stats['population'] for d, stats in district_stats.items()},\n",
        "        vtd_pop, old_district, new_district, pop_lower_bound, pop_upper_bound\n",
        "    ):\n",
        "        return False, 'population'\n",
        "\n",
        "    # Check compactness\n",
        "    if not is_flip_compactness_balanced(\n",
        "        gdf, vtd_id, vtd_geom, old_district, new_district, compactness_lower_bound\n",
        "    ):\n",
        "        return False, 'compactness'\n",
        "\n",
        "    # Check vote efficiency\n",
        "    if not does_flip_improve_vote_efficiency(\n",
        "        district_stats, vtd_r_votes, vtd_d_votes, old_district, new_district, party_preference\n",
        "    ):\n",
        "        return False, 'vote_efficiency'\n",
        "\n",
        "    return True, None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WVwHacfuqT-"
      },
      "source": [
        "### Flip and Execution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "8e6N5IX6uxFE"
      },
      "outputs": [],
      "source": [
        "def find_boundary_vtds(gdf, graph):\n",
        "    \"\"\"Find all VTDs that are on district boundaries.\"\"\"\n",
        "    boundary_vtds = []\n",
        "\n",
        "    for idx in gdf.index:\n",
        "        current_dist = gdf.loc[idx, 'district']\n",
        "        neighbors = list(graph.neighbors(idx))\n",
        "        neighbor_dists = gdf.loc[neighbors, 'district'].values\n",
        "\n",
        "        if len(neighbors) > 0 and any(neighbor_dists != current_dist):\n",
        "            boundary_vtds.append(idx)\n",
        "\n",
        "    return boundary_vtds\n",
        "\n",
        "\n",
        "def propose_flip(gdf, graph):\n",
        "    \"\"\"Propose moving a random boundary VTD to a neighboring district.\"\"\"\n",
        "    boundary_vtds = find_boundary_vtds(gdf, graph)\n",
        "\n",
        "    if not boundary_vtds:\n",
        "        return None, None, None, None, None, None, None\n",
        "\n",
        "    # Pick random boundary VTD\n",
        "    vtd = random.choice(boundary_vtds)\n",
        "    old_dist = gdf.loc[vtd, 'district']\n",
        "    vtd_pop = gdf.loc[vtd, 'TOTAL']\n",
        "    vtd_r_votes = gdf.loc[vtd, 'VoterReg_R']\n",
        "    vtd_d_votes = gdf.loc[vtd, 'VoterReg_D']\n",
        "    vtd_geom = gdf.loc[vtd, 'geometry']\n",
        "\n",
        "    # Find neighboring districts\n",
        "    neighbors = list(graph.neighbors(vtd))\n",
        "    neighbor_dists = [\n",
        "        gdf.loc[n, 'district'] for n in neighbors\n",
        "        if gdf.loc[n, 'district'] != old_dist\n",
        "    ]\n",
        "\n",
        "    if not neighbor_dists:\n",
        "        return None, None, None, None, None, None, None\n",
        "\n",
        "    new_dist = random.choice(neighbor_dists)\n",
        "    return vtd, old_dist, new_dist, vtd_geom, vtd_pop, vtd_r_votes, vtd_d_votes\n",
        "\n",
        "\n",
        "def execute_flip(gdf, district_stats, vtd_id, vtd_geom, vtd_pop, vtd_r_votes, vtd_d_votes, old_district, new_district):\n",
        "    \"\"\"\n",
        "    Execute a flip by updating gdf and district_stats.\n",
        "    \"\"\"\n",
        "    # Update gdf\n",
        "    gdf.loc[vtd_id, 'district'] = new_district\n",
        "\n",
        "    # Update OLD district stats\n",
        "    district_stats[old_district]['population'] -= vtd_pop\n",
        "    district_stats[old_district]['VoterReg_R'] -= vtd_r_votes\n",
        "    district_stats[old_district]['VoterReg_D'] -= vtd_d_votes\n",
        "\n",
        "    # Recalculate old district geometry and compactness\n",
        "    old_district_data = gdf[gdf['district'] == old_district]\n",
        "    if len(old_district_data) > 0:\n",
        "        old_district_geom = old_district_data.unary_union\n",
        "        district_stats[old_district]['area'] = old_district_geom.area\n",
        "        district_stats[old_district]['perimeter'] = old_district_geom.length\n",
        "\n",
        "        if old_district_geom.length > 0:\n",
        "            district_stats[old_district]['polsby_popper'] = (4 * np.pi * old_district_geom.area) / (old_district_geom.length ** 2)\n",
        "        else:\n",
        "            district_stats[old_district]['polsby_popper'] = 0\n",
        "\n",
        "    # Recalculate old district wasted votes\n",
        "    old_wasted_d, old_wasted_r = wasted_votes(\n",
        "        district_stats[old_district]['VoterReg_R'],\n",
        "        district_stats[old_district]['VoterReg_D']\n",
        "    )\n",
        "    district_stats[old_district]['wasted_D_votes'] = old_wasted_d\n",
        "    district_stats[old_district]['wasted_R_votes'] = old_wasted_r\n",
        "\n",
        "    # Update NEW district stats\n",
        "    district_stats[new_district]['population'] += vtd_pop\n",
        "    district_stats[new_district]['VoterReg_R'] += vtd_r_votes\n",
        "    district_stats[new_district]['VoterReg_D'] += vtd_d_votes\n",
        "\n",
        "    # Recalculate new district geometry and compactness\n",
        "    new_district_data = gdf[gdf['district'] == new_district]\n",
        "    new_district_geom = new_district_data.unary_union\n",
        "    district_stats[new_district]['area'] = new_district_geom.area\n",
        "    district_stats[new_district]['perimeter'] = new_district_geom.length\n",
        "\n",
        "    if new_district_geom.length > 0:\n",
        "        district_stats[new_district]['polsby_popper'] = (4 * np.pi * new_district_geom.area) / (new_district_geom.length ** 2)\n",
        "    else:\n",
        "        district_stats[new_district]['polsby_popper'] = 0\n",
        "\n",
        "    # Recalculate new district wasted votes\n",
        "    new_wasted_d, new_wasted_r = wasted_votes(\n",
        "        district_stats[new_district]['VoterReg_R'],\n",
        "        district_stats[new_district]['VoterReg_D']\n",
        "    )\n",
        "    district_stats[new_district]['wasted_D_votes'] = new_wasted_d\n",
        "    district_stats[new_district]['wasted_R_votes'] = new_wasted_r"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vO6DUi7zu-2v"
      },
      "source": [
        "### Redistricting Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "v2unMxPbvAw1"
      },
      "outputs": [],
      "source": [
        "def redistrict_iterative(gdf, graph, num_iterations=1000, pop_tolerance=0.05,\n",
        "                         compactness_lower_bound=0.15, party_preference='D', acceptance_rate=0.95,\n",
        "                         verbose=True):\n",
        "    \"\"\"\n",
        "\n",
        "    Parameters:\n",
        "    - gdf: GeoDataFrame with VTD data and initialized districts\n",
        "    - graph: Pre-built adjacency graph\n",
        "    - num_iterations: Number of iterations to run\n",
        "    - pop_tolerance: Population balance tolerance (default 0.05 = Â±5%)\n",
        "    - compactness_lower_bound: Lower bound for Polsby-Popper score\n",
        "    - party_preference: 'D', 'R', or None for vote efficiency\n",
        "    - acceptance_rate: Probability of accepting valid flips\n",
        "    - verbose: Print progress updates\n",
        "\n",
        "    Returns:\n",
        "    - gdf_redistricted: Updated GeoDataFrame with new district assignments\n",
        "    - district_stats_new: Updated district statistics\n",
        "    - metrics: Dictionary with execution metrics (includes rejection_counts)\n",
        "    - stats_history: List of district stats at each iteration\n",
        "    - gdf_snapshots: Dictionary of GeoDataFrame snapshots at every 100 iterations\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"=\"*60)\n",
        "    print(\"STARTING ITERATIVE REDISTRICTING\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Step 1: Create initial district stats\n",
        "    print(\"\\n[1/3] Calculating initial district statistics...\")\n",
        "    start_time = time.time()\n",
        "    district_stats = district_stats_object(gdf, graph)\n",
        "    stats_time = time.time() - start_time\n",
        "    print(f\"âœ“ Calculated stats for {len(district_stats)} districts in {stats_time:.2f}s\")\n",
        "\n",
        "    # Print initial district stats\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"INITIAL DISTRICT STATISTICS\")\n",
        "    print(\"=\"*60)\n",
        "    for dist_id, stats in sorted(district_stats.items()):\n",
        "        print(f\"\\nDistrict {dist_id}:\")\n",
        "        print(f\"  Population: {stats['population']:,}\")\n",
        "        print(f\"  Polsby-Popper: {stats['polsby_popper']:.4f}\")\n",
        "        print(f\"  Dem Votes: {stats['VoterReg_D']:,} | Rep Votes: {stats['VoterReg_R']:,}\")\n",
        "        print(f\"  Wasted D: {stats['wasted_D_votes']:,} | Wasted R: {stats['wasted_R_votes']:,}\")\n",
        "\n",
        "    # Calculate aggregate metrics\n",
        "    total_wasted_d = sum(stats['wasted_D_votes'] for stats in district_stats.values())\n",
        "    total_wasted_r = sum(stats['wasted_R_votes'] for stats in district_stats.values())\n",
        "    avg_compactness = np.mean([stats['polsby_popper'] for stats in district_stats.values()])\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"AGGREGATE METRICS\")\n",
        "    print(\"=\"*60)\n",
        "    print(f\"Total wasted Democratic votes: {total_wasted_d:,}\")\n",
        "    print(f\"Total wasted Republican votes: {total_wasted_r:,}\")\n",
        "    print(f\"Efficiency gap: {abs(total_wasted_d - total_wasted_r):,}\")\n",
        "    print(f\"Average compactness: {avg_compactness:.4f}\")\n",
        "\n",
        "    # Step 2: Calculate population bounds\n",
        "    print(\"\\n[2/3] Calculating population bounds...\")\n",
        "    pop_lower, pop_upper = calculate_pop_bounds(district_stats, pop_tolerance)\n",
        "    total_pop = sum(stats['population'] for stats in district_stats.values())\n",
        "    ideal_pop = total_pop / len(district_stats)\n",
        "    print(f\"âœ“ Ideal population: {ideal_pop:,.0f}\")\n",
        "    print(f\"  Lower bound: {pop_lower:,.0f} ({(1-pop_tolerance)*100:.0f}%)\")\n",
        "    print(f\"  Upper bound: {pop_upper:,.0f} ({(1+pop_tolerance)*100:.0f}%)\")\n",
        "    print(f\"  Compactness lower bound: {compactness_lower_bound:.4f}\")\n",
        "\n",
        "    # Step 3: Initialize tracking\n",
        "    stats_history = []\n",
        "    gdf_snapshots = {}\n",
        "\n",
        "    # Save initial state\n",
        "    initial_metrics = {\n",
        "        'iteration': 0,\n",
        "        'total_wasted_d': total_wasted_d,\n",
        "        'total_wasted_r': total_wasted_r,\n",
        "        'efficiency_gap': abs(total_wasted_d - total_wasted_r),\n",
        "        'avg_compactness': avg_compactness,\n",
        "        'accepted': False,\n",
        "        'district_stats': {\n",
        "            dist_id: {\n",
        "                'population': stats['population'],\n",
        "                'polsby_popper': stats['polsby_popper'],\n",
        "                'VoterReg_D': stats['VoterReg_D'],\n",
        "                'VoterReg_R': stats['VoterReg_R'],\n",
        "                'wasted_D_votes': stats['wasted_D_votes'],\n",
        "                'wasted_R_votes': stats['wasted_R_votes']\n",
        "            }\n",
        "            for dist_id, stats in district_stats.items()\n",
        "        }\n",
        "    }\n",
        "    stats_history.append(initial_metrics)\n",
        "    gdf_snapshots[0] = gdf.copy()  # Save initial GDF\n",
        "\n",
        "    # Step 4: Run iterations\n",
        "    print(\"\\n[3/3] Running redistricting iterations...\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    propose_times = []\n",
        "    check_times = []\n",
        "    execute_times = []\n",
        "    accepted_flips = 0\n",
        "    rejected_flips = 0\n",
        "\n",
        "    # Track rejection reasons\n",
        "    rejection_counts = {\n",
        "        'contiguity': 0,\n",
        "        'population': 0,\n",
        "        'compactness': 0,\n",
        "        'vote_efficiency': 0,\n",
        "        'no_proposal': 0\n",
        "    }\n",
        "\n",
        "    iteration_start = time.time()\n",
        "\n",
        "    for i in range(num_iterations):\n",
        "        # Propose\n",
        "        start_propose = time.time()\n",
        "        vtd, old_dist, new_dist, vtd_geom, vtd_pop, vtd_r_votes, vtd_d_votes = propose_flip(gdf=gdf, graph=graph)\n",
        "        propose_time = time.time() - start_propose\n",
        "        propose_times.append(propose_time)\n",
        "\n",
        "        if vtd is None:\n",
        "            rejected_flips += 1\n",
        "            rejection_counts['no_proposal'] += 1\n",
        "            if verbose and (i + 1) % 100 == 0:\n",
        "                print(f\"Iteration {i+1}/{num_iterations}: No valid proposal\")\n",
        "\n",
        "            # Still save stats even if no proposal\n",
        "            total_wasted_d = sum(stats['wasted_D_votes'] for stats in district_stats.values())\n",
        "            total_wasted_r = sum(stats['wasted_R_votes'] for stats in district_stats.values())\n",
        "            avg_compactness = np.mean([stats['polsby_popper'] for stats in district_stats.values()])\n",
        "\n",
        "            iteration_metrics = {\n",
        "                'iteration': i + 1,\n",
        "                'total_wasted_d': total_wasted_d,\n",
        "                'total_wasted_r': total_wasted_r,\n",
        "                'efficiency_gap': abs(total_wasted_d - total_wasted_r),\n",
        "                'avg_compactness': avg_compactness,\n",
        "                'accepted': False,\n",
        "                'district_stats': {\n",
        "                    dist_id: {\n",
        "                        'population': stats['population'],\n",
        "                        'polsby_popper': stats['polsby_popper'],\n",
        "                        'VoterReg_D': stats['VoterReg_D'],\n",
        "                        'VoterReg_R': stats['VoterReg_R'],\n",
        "                        'wasted_D_votes': stats['wasted_D_votes'],\n",
        "                        'wasted_R_votes': stats['wasted_R_votes']\n",
        "                    }\n",
        "                    for dist_id, stats in district_stats.items()\n",
        "                }\n",
        "            }\n",
        "            stats_history.append(iteration_metrics)\n",
        "            continue\n",
        "\n",
        "        # Check with rejection tracking\n",
        "        start_check = time.time()\n",
        "        is_valid, rejection_reason = check_flip(\n",
        "            gdf, graph, district_stats, vtd,\n",
        "            vtd_geom=vtd_geom, vtd_pop=vtd_pop,\n",
        "            vtd_r_votes=vtd_r_votes, vtd_d_votes=vtd_d_votes,\n",
        "            old_district=old_dist, new_district=new_dist,\n",
        "            pop_lower_bound=pop_lower, pop_upper_bound=pop_upper,\n",
        "            compactness_lower_bound=compactness_lower_bound,\n",
        "            party_preference=party_preference\n",
        "        )\n",
        "        check_time = time.time() - start_check\n",
        "        check_times.append(check_time)\n",
        "\n",
        "        # Execute if valid\n",
        "        flip_accepted = False\n",
        "        if is_valid and random.random() < acceptance_rate:\n",
        "            start_execute = time.time()\n",
        "            execute_flip(gdf, district_stats, vtd, vtd_geom, vtd_pop,\n",
        "                        vtd_r_votes, vtd_d_votes, old_dist, new_dist)\n",
        "            execute_time = time.time() - start_execute\n",
        "            execute_times.append(execute_time)\n",
        "            accepted_flips += 1\n",
        "            flip_accepted = True\n",
        "\n",
        "            if verbose and (i + 1) % 100 == 0:\n",
        "                print(f\"Iteration {i+1}/{num_iterations}: âœ“ ACCEPTED (VTD {vtd}: {old_dist}â†’{new_dist})\")\n",
        "        else:\n",
        "            rejected_flips += 1\n",
        "            if rejection_reason:\n",
        "                rejection_counts[rejection_reason] += 1\n",
        "            if verbose and (i + 1) % 100 == 0:\n",
        "                reason_str = f\" ({rejection_reason})\" if rejection_reason else \"\"\n",
        "                print(f\"Iteration {i+1}/{num_iterations}: âœ— Rejected{reason_str}\")\n",
        "\n",
        "        # Save stats after each iteration\n",
        "        total_wasted_d = sum(stats['wasted_D_votes'] for stats in district_stats.values())\n",
        "        total_wasted_r = sum(stats['wasted_R_votes'] for stats in district_stats.values())\n",
        "        avg_compactness = np.mean([stats['polsby_popper'] for stats in district_stats.values()])\n",
        "\n",
        "        iteration_metrics = {\n",
        "            'iteration': i + 1,\n",
        "            'total_wasted_d': total_wasted_d,\n",
        "            'total_wasted_r': total_wasted_r,\n",
        "            'efficiency_gap': abs(total_wasted_d - total_wasted_r),\n",
        "            'avg_compactness': avg_compactness,\n",
        "            'accepted': flip_accepted,\n",
        "            'district_stats': {\n",
        "                dist_id: {\n",
        "                    'population': stats['population'],\n",
        "                    'polsby_popper': stats['polsby_popper'],\n",
        "                    'VoterReg_D': stats['VoterReg_D'],\n",
        "                    'VoterReg_R': stats['VoterReg_R'],\n",
        "                    'wasted_D_votes': stats['wasted_D_votes'],\n",
        "                    'wasted_R_votes': stats['wasted_R_votes']\n",
        "                }\n",
        "                for dist_id, stats in district_stats.items()\n",
        "            }\n",
        "        }\n",
        "        stats_history.append(iteration_metrics)\n",
        "\n",
        "        # Save GDF snapshot every 100 iterations\n",
        "        if (i + 1) % 100 == 0:\n",
        "            gdf_snapshots[i + 1] = gdf.copy()\n",
        "            if verbose:\n",
        "                print(f\"  ðŸ“¸ Saved GDF snapshot at iteration {i+1}\")\n",
        "\n",
        "    total_iteration_time = time.time() - iteration_start\n",
        "\n",
        "    # Summary\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"REDISTRICTING COMPLETE\")\n",
        "    print(\"=\"*60)\n",
        "    print(f\"\\nTotal iterations: {num_iterations}\")\n",
        "    print(f\"Accepted flips: {accepted_flips} ({accepted_flips/num_iterations*100:.1f}%)\")\n",
        "    print(f\"Rejected flips: {rejected_flips} ({rejected_flips/num_iterations*100:.1f}%)\")\n",
        "    print(f\"\\nTotal time: {total_iteration_time:.2f}s\")\n",
        "    print(f\"Time per iteration: {total_iteration_time/num_iterations*1000:.2f}ms\")\n",
        "\n",
        "    if len(propose_times) > 0:\n",
        "        print(f\"\\nAverage propose time: {np.mean(propose_times)*1000:.2f}ms\")\n",
        "    if len(check_times) > 0:\n",
        "        print(f\"Average check time: {np.mean(check_times)*1000:.2f}ms\")\n",
        "    if len(execute_times) > 0:\n",
        "        print(f\"Average execute time: {np.mean(execute_times)*1000:.2f}ms\")\n",
        "\n",
        "    # Print rejection summary\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"REJECTION REASONS\")\n",
        "    print(\"=\"*60)\n",
        "    total_rejections = sum(rejection_counts.values())\n",
        "    for reason, count in sorted(rejection_counts.items(), key=lambda x: -x[1]):\n",
        "        pct = (count / total_rejections * 100) if total_rejections > 0 else 0\n",
        "        print(f\"{reason:20s}: {count:5d} ({pct:5.1f}%)\")\n",
        "\n",
        "    # Print final district stats\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"FINAL DISTRICT STATISTICS\")\n",
        "    print(\"=\"*60)\n",
        "    for dist_id, stats in sorted(district_stats.items()):\n",
        "        print(f\"\\nDistrict {dist_id}:\")\n",
        "        print(f\"  Population: {stats['population']:,}\")\n",
        "        print(f\"  Polsby-Popper: {stats['polsby_popper']:.4f}\")\n",
        "        print(f\"  Dem Votes: {stats['VoterReg_D']:,} | Rep Votes: {stats['VoterReg_R']:,}\")\n",
        "        print(f\"  Wasted D: {stats['wasted_D_votes']:,} | Wasted R: {stats['wasted_R_votes']:,}\")\n",
        "\n",
        "    # Calculate final aggregate metrics\n",
        "    total_wasted_d = sum(stats['wasted_D_votes'] for stats in district_stats.values())\n",
        "    total_wasted_r = sum(stats['wasted_R_votes'] for stats in district_stats.values())\n",
        "    avg_compactness = np.mean([stats['polsby_popper'] for stats in district_stats.values()])\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"AGGREGATE METRICS\")\n",
        "    print(\"=\"*60)\n",
        "    print(f\"Total wasted Democratic votes: {total_wasted_d:,}\")\n",
        "    print(f\"Total wasted Republican votes: {total_wasted_r:,}\")\n",
        "    print(f\"Efficiency gap: {abs(total_wasted_d - total_wasted_r):,}\")\n",
        "    print(f\"Average compactness: {avg_compactness:.4f}\")\n",
        "\n",
        "    print(f\" Saved {len(gdf_snapshots)} GDF snapshots\")\n",
        "    print(f\"   Snapshot iterations: {sorted(gdf_snapshots.keys())}\")\n",
        "\n",
        "    # Prepare output\n",
        "    gdf_redistricted = gdf.copy()\n",
        "    district_stats_new = district_stats.copy()\n",
        "\n",
        "    metrics = {\n",
        "        'num_iterations': num_iterations,\n",
        "        'accepted_flips': accepted_flips,\n",
        "        'rejected_flips': rejected_flips,\n",
        "        'acceptance_rate': accepted_flips / num_iterations,\n",
        "        'total_time': total_iteration_time,\n",
        "        'avg_propose_time': np.mean(propose_times) if propose_times else 0,\n",
        "        'avg_check_time': np.mean(check_times) if check_times else 0,\n",
        "        'avg_execute_time': np.mean(execute_times) if execute_times else 0,\n",
        "        'total_wasted_d': total_wasted_d,\n",
        "        'total_wasted_r': total_wasted_r,\n",
        "        'efficiency_gap': abs(total_wasted_d - total_wasted_r),\n",
        "        'avg_compactness': avg_compactness,\n",
        "        'rejection_counts': rejection_counts  # NEW\n",
        "    }\n",
        "\n",
        "    return gdf_redistricted, district_stats_new, metrics, stats_history, gdf_snapshots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bSORigqvLuW"
      },
      "source": [
        "### Visualisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "udXEv2YovOby"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# SECTION 8: VISUALIZATION FUNCTIONS (FULLY STYLED)\n",
        "# ============================================================================\n",
        "\n",
        "def plot_single_map(gdf, column, title, ax, cmap='tab10', show_legend=False):\n",
        "    \"\"\"Plot a single map on given axis.\"\"\"\n",
        "    gdf.plot(column=column, \n",
        "             cmap=cmap, \n",
        "             edgecolor='black', \n",
        "             linewidth=0.1,\n",
        "             legend=show_legend,\n",
        "             ax=ax)\n",
        "    ax.set_title(title, fontsize=14, fontweight='bold')\n",
        "    ax.axis('off')\n",
        "\n",
        "\n",
        "def create_district_colormap():\n",
        "    \"\"\"\n",
        "    Create professional colormap for 9 districts.\n",
        "    Uses muted, academic colors instead of bright tab10.\n",
        "    \"\"\"\n",
        "    from matplotlib.colors import ListedColormap\n",
        "    \n",
        "    # Professional academic palette for 9 districts\n",
        "    district_colors = [\n",
        "        '#4e79a7',  # Muted blue\n",
        "        '#f28e2b',  # Muted orange\n",
        "        '#e15759',  # Muted red\n",
        "        '#76b7b2',  # Muted teal\n",
        "        '#59a14f',  # Muted green\n",
        "        '#edc948',  # Muted yellow\n",
        "        '#b07aa1',  # Muted purple\n",
        "        '#ff9da7',  # Muted pink\n",
        "        '#9c755f',  # Muted brown\n",
        "    ]\n",
        "    \n",
        "    return ListedColormap(district_colors)\n",
        "\n",
        "\n",
        "def plot_redistricting_evolution(gdf_snapshots, stats_history, figsize=(28, 14), save_path=None):\n",
        "    \"\"\"\n",
        "    Plot evolution of redistricting with maps, statistics, AND population bar charts.\n",
        "    FULLY STYLED: Custom district colors, Times New Roman, thinner borders.\n",
        "    \n",
        "    CHANGED: Larger figure size, thinner VTD borders, custom district colormap\n",
        "    \"\"\"\n",
        "    from matplotlib.gridspec import GridSpec\n",
        "    \n",
        "    # Get sorted iterations\n",
        "    iterations = sorted(gdf_snapshots.keys())\n",
        "    n_snapshots = len(iterations)\n",
        "    \n",
        "    # Create figure with custom grid (3 rows: maps, metrics, population bars)\n",
        "    fig = plt.figure(figsize=figsize)\n",
        "    gs = GridSpec(3, n_snapshots, figure=fig, hspace=0.4, wspace=0.3)\n",
        "    \n",
        "    # Custom professional colormap for districts\n",
        "    cmap_districts = create_district_colormap()\n",
        "    \n",
        "    # Plot each snapshot\n",
        "    for idx, iter_num in enumerate(iterations):\n",
        "        gdf_snap = gdf_snapshots[iter_num]\n",
        "        \n",
        "        # Find corresponding stats\n",
        "        stats = next((s for s in stats_history if s['iteration'] == iter_num), None)\n",
        "        if stats is None:\n",
        "            continue\n",
        "        \n",
        "        # Calculate Democratic districts\n",
        "        dem_districts = 0\n",
        "        for dist_id, dist_stats in stats['district_stats'].items():\n",
        "            if dist_stats['VoterReg_D'] > dist_stats['VoterReg_R']:\n",
        "                dem_districts += 1\n",
        "        \n",
        "        total_districts = len(stats['district_stats'])\n",
        "        \n",
        "        # Row 1: Map (STYLED)\n",
        "        ax_map = fig.add_subplot(gs[0, idx])\n",
        "        gdf_snap.plot(column='district', \n",
        "                     cmap=cmap_districts,           # CHANGED: Custom colors\n",
        "                     edgecolor='black', \n",
        "                     linewidth=0.15,                # CHANGED: Thinner borders (was 0.5)\n",
        "                     ax=ax_map,\n",
        "                     legend=False)\n",
        "        ax_map.set_title(f'Iteration {iter_num}\\nDem Districts: {dem_districts}/{total_districts}',\n",
        "                        fontsize=12, fontweight='bold')\n",
        "        ax_map.axis('off')\n",
        "        \n",
        "        # Row 2: Key metrics text\n",
        "        ax_text = fig.add_subplot(gs[1, idx])\n",
        "        ax_text.axis('off')\n",
        "        \n",
        "        metrics_text = f\"\"\"\n",
        "Efficiency Gap: {stats['efficiency_gap']:,}\n",
        "\n",
        "Wasted Votes:\n",
        "  D: {stats['total_wasted_d']:,}\n",
        "  R: {stats['total_wasted_r']:,}\n",
        "\n",
        "Avg Compactness:\n",
        "  {stats['avg_compactness']:.4f}\n",
        "        \"\"\"\n",
        "        \n",
        "        ax_text.text(0.1, 0.5, metrics_text.strip(), \n",
        "                    fontsize=10,                    # CHANGED: Slightly larger (was 9)\n",
        "                    family='Times New Roman',\n",
        "                    verticalalignment='center',\n",
        "                    transform=ax_text.transAxes)\n",
        "        \n",
        "        # Row 3: District Population Bar Chart\n",
        "        ax_pop = fig.add_subplot(gs[2, idx])\n",
        "        \n",
        "        # Get district IDs and populations\n",
        "        district_ids = sorted(stats['district_stats'].keys())\n",
        "        populations = [stats['district_stats'][d]['population'] for d in district_ids]\n",
        "        \n",
        "        # Color bars by party winner (KEEP red/blue for partisan)\n",
        "        colors = []\n",
        "        for dist_id in district_ids:\n",
        "            if stats['district_stats'][dist_id]['VoterReg_D'] > stats['district_stats'][dist_id]['VoterReg_R']:\n",
        "                colors.append(COLORS['democratic'])  # Blue\n",
        "            else:\n",
        "                colors.append(COLORS['republican'])  # Red\n",
        "        \n",
        "        # Calculate ideal population line\n",
        "        total_pop = sum(populations)\n",
        "        ideal_pop = total_pop / len(district_ids)\n",
        "        \n",
        "        # Plot bars\n",
        "        ax_pop.bar(district_ids, populations, color=colors, alpha=0.75, \n",
        "                   edgecolor='black', linewidth=1.2)\n",
        "        ax_pop.axhline(ideal_pop, color='black', linestyle='--', linewidth=1.8, alpha=0.7)\n",
        "        \n",
        "        ax_pop.set_xlabel('District', fontsize=9)\n",
        "        ax_pop.set_ylabel('Population', fontsize=9)\n",
        "        ax_pop.set_title('District Populations', fontsize=10, fontweight='bold')\n",
        "        ax_pop.tick_params(labelsize=8)\n",
        "        ax_pop.grid(True, alpha=0.3, axis='y')\n",
        "        ax_pop.set_ylim([0, max(populations) * 1.1])\n",
        "    \n",
        "    plt.suptitle('Redistricting Evolution: Republican Gerrymandering Algorithm', \n",
        "                 fontsize=18, fontweight='bold', y=0.98)\n",
        "    \n",
        "    if save_path:\n",
        "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "        print(f\"âœ“ Saved figure to {save_path}\")\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_metrics_over_time(stats_history, figsize=(16, 10), save_path=None):\n",
        "    \"\"\"\n",
        "    Plot how key metrics evolve over iterations.\n",
        "    STYLED with consistent colors and Times New Roman font.\n",
        "    \"\"\"\n",
        "    \n",
        "    iterations = [s['iteration'] for s in stats_history]\n",
        "    efficiency_gaps = [s['efficiency_gap'] for s in stats_history]\n",
        "    avg_compactness = [s['avg_compactness'] for s in stats_history]\n",
        "    total_wasted_d = [s['total_wasted_d'] for s in stats_history]\n",
        "    total_wasted_r = [s['total_wasted_r'] for s in stats_history]\n",
        "    \n",
        "    # Count Democratic districts at each iteration\n",
        "    dem_districts = []\n",
        "    for stats in stats_history:\n",
        "        count = sum(1 for dist_stats in stats['district_stats'].values() \n",
        "                   if dist_stats['VoterReg_D'] > dist_stats['VoterReg_R'])\n",
        "        dem_districts.append(count)\n",
        "    \n",
        "    # Calculate rolling acceptance rate (window size = 50)\n",
        "    accepted = [1 if s['accepted'] else 0 for s in stats_history]\n",
        "    window_size = 50\n",
        "    acceptance_rates = []\n",
        "    for i in range(len(accepted)):\n",
        "        if i < window_size:\n",
        "            acceptance_rates.append(np.mean(accepted[:i+1]) if i > 0 else 0)\n",
        "        else:\n",
        "            acceptance_rates.append(np.mean(accepted[i-window_size+1:i+1]))\n",
        "    \n",
        "    # Create 2x3 subplot grid\n",
        "    fig, axes = plt.subplots(2, 3, figsize=figsize)\n",
        "    \n",
        "    # Plot 1: Efficiency Gap (Navy Blue)\n",
        "    axes[0, 0].plot(iterations, efficiency_gaps, linewidth=2.5, \n",
        "                    color=COLORS['efficiency_gap'])\n",
        "    axes[0, 0].set_title('Efficiency Gap', fontweight='bold', fontsize=13)\n",
        "    axes[0, 0].set_xlabel('Iteration', fontsize=11)\n",
        "    axes[0, 0].set_ylabel('Efficiency Gap', fontsize=11)\n",
        "    axes[0, 0].grid(True, alpha=0.3)\n",
        "    axes[0, 0].tick_params(labelsize=10)\n",
        "    \n",
        "    # Plot 2: Average Compactness (Forest Green)\n",
        "    axes[0, 1].plot(iterations, avg_compactness, linewidth=2.5, \n",
        "                    color=COLORS['compactness'])\n",
        "    axes[0, 1].set_title('Average Compactness (Polsby-Popper)', fontweight='bold', fontsize=13)\n",
        "    axes[0, 1].set_xlabel('Iteration', fontsize=11)\n",
        "    axes[0, 1].set_ylabel('Polsby-Popper Score', fontsize=11)\n",
        "    axes[0, 1].grid(True, alpha=0.3)\n",
        "    axes[0, 1].tick_params(labelsize=10)\n",
        "    \n",
        "    # Plot 3: Wasted Votes (Blue/Red for partisan)\n",
        "    axes[1, 0].plot(iterations, total_wasted_d, linewidth=2.5, \n",
        "                    label='Democratic', color=COLORS['democratic'])\n",
        "    axes[1, 0].plot(iterations, total_wasted_r, linewidth=2.5, \n",
        "                    label='Republican', color=COLORS['republican'])\n",
        "    axes[1, 0].set_title('Wasted Votes', fontweight='bold', fontsize=13)\n",
        "    axes[1, 0].set_xlabel('Iteration', fontsize=11)\n",
        "    axes[1, 0].set_ylabel('Wasted Votes', fontsize=11)\n",
        "    axes[1, 0].legend(fontsize=10)\n",
        "    axes[1, 0].grid(True, alpha=0.3)\n",
        "    axes[1, 0].tick_params(labelsize=10)\n",
        "    \n",
        "    # Plot 4: Democratic Districts (Purple)\n",
        "    axes[1, 1].plot(iterations, dem_districts, linewidth=2.5, \n",
        "                    color=COLORS['scatter'])\n",
        "    axes[1, 1].set_title('Democratic Districts', fontweight='bold', fontsize=13)\n",
        "    axes[1, 1].set_xlabel('Iteration', fontsize=11)\n",
        "    axes[1, 1].set_ylabel('Number of Dem Districts', fontsize=11)\n",
        "    axes[1, 1].set_ylim([0, 10])\n",
        "    axes[1, 1].grid(True, alpha=0.3)\n",
        "    axes[1, 1].tick_params(labelsize=10)\n",
        "    \n",
        "    # Plot 5: Acceptance Rate (Dark Orange)\n",
        "    axes[0, 2].plot(iterations, acceptance_rates, linewidth=2.5, \n",
        "                    color=COLORS['acceptance_rate'])\n",
        "    axes[0, 2].set_title('Acceptance Rate (Rolling 50)', fontweight='bold', fontsize=13)\n",
        "    axes[0, 2].set_xlabel('Iteration', fontsize=11)\n",
        "    axes[0, 2].set_ylabel('Acceptance Rate', fontsize=11)\n",
        "    axes[0, 2].set_ylim([0, 1])\n",
        "    axes[0, 2].grid(True, alpha=0.3)\n",
        "    axes[0, 2].tick_params(labelsize=10)\n",
        "    \n",
        "    # Plot 6: Efficiency Gap vs Compactness Scatter\n",
        "    # Use sequential blue shading (light to dark) instead of viridis\n",
        "    from matplotlib.colors import LinearSegmentedColormap\n",
        "    colors_gradient = ['#c6dbef', '#9ecae1', '#6baed6', '#4292c6', '#2171b5', '#084594']\n",
        "    n_bins = 100\n",
        "    cmap_custom = LinearSegmentedColormap.from_list('blues_custom', colors_gradient, N=n_bins)\n",
        "    \n",
        "    scatter = axes[1, 2].scatter(avg_compactness, efficiency_gaps, \n",
        "                                 c=iterations, cmap=cmap_custom, \n",
        "                                 s=50, alpha=0.7, edgecolors='black', linewidth=0.7)\n",
        "    axes[1, 2].set_title('Efficiency Gap vs Compactness', fontweight='bold', fontsize=13)\n",
        "    axes[1, 2].set_xlabel('Average Compactness', fontsize=11)\n",
        "    axes[1, 2].set_ylabel('Efficiency Gap', fontsize=11)\n",
        "    axes[1, 2].grid(True, alpha=0.3)\n",
        "    axes[1, 2].tick_params(labelsize=10)\n",
        "    \n",
        "    # Add colorbar\n",
        "    cbar = plt.colorbar(scatter, ax=axes[1, 2])\n",
        "    cbar.set_label('Iteration', rotation=270, labelpad=15, fontsize=10)\n",
        "    cbar.ax.tick_params(labelsize=9)\n",
        "    \n",
        "    plt.suptitle('Redistricting Metrics Over Time', fontsize=18, fontweight='bold')\n",
        "    plt.tight_layout()\n",
        "    \n",
        "    if save_path:\n",
        "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "        print(f\"âœ“ Saved figure to {save_path}\")\n",
        "    \n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_rejection_reasons(metrics, figsize=(10, 6), save_path=None):\n",
        "    \"\"\"\n",
        "    Plot bar chart of rejection reasons.\n",
        "    STYLED with consistent colors and Times New Roman font.\n",
        "    \"\"\"\n",
        "    \n",
        "    rejection_counts = metrics['rejection_counts']\n",
        "    \n",
        "    # Sort by count (descending)\n",
        "    sorted_reasons = sorted(rejection_counts.items(), key=lambda x: -x[1])\n",
        "    reasons = [r[0].replace('_', ' ').title() for r in sorted_reasons]\n",
        "    counts = [r[1] for r in sorted_reasons]\n",
        "    \n",
        "    # Calculate percentages\n",
        "    total = sum(counts)\n",
        "    percentages = [(c / total * 100) if total > 0 else 0 for c in counts]\n",
        "    \n",
        "    # Create figure\n",
        "    fig, ax = plt.subplots(figsize=figsize)\n",
        "    \n",
        "    # Use consistent color palette\n",
        "    bar_colors = [\n",
        "        COLORS['efficiency_gap'],   # Navy blue\n",
        "        COLORS['compactness'],      # Forest green\n",
        "        COLORS['acceptance_rate'],  # Dark orange\n",
        "        COLORS['scatter'],          # Royal purple\n",
        "        COLORS['neutral']           # Gray\n",
        "    ]\n",
        "    \n",
        "    # Create bars\n",
        "    bars = ax.bar(reasons, counts, color=bar_colors[:len(reasons)], \n",
        "                  alpha=0.8, edgecolor='black', linewidth=1.5)\n",
        "    \n",
        "    # Add value labels on bars\n",
        "    for i, (bar, count, pct) in enumerate(zip(bars, counts, percentages)):\n",
        "        height = bar.get_height()\n",
        "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
        "                f'{count:,}\\n({pct:.1f}%)',\n",
        "                ha='center', va='bottom', fontweight='bold', fontsize=11)\n",
        "    \n",
        "    # Formatting\n",
        "    ax.set_xlabel('Rejection Reason', fontsize=13, fontweight='bold')\n",
        "    ax.set_ylabel('Number of Rejections', fontsize=13, fontweight='bold')\n",
        "    ax.set_title('Flip Rejection Reasons', fontsize=15, fontweight='bold', pad=20)\n",
        "    ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
        "    ax.tick_params(labelsize=11)\n",
        "    \n",
        "    # Rotate x-axis labels\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    \n",
        "    if save_path:\n",
        "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "        print(f\"âœ“ Saved rejection reasons chart to {save_path}\")\n",
        "    \n",
        "    plt.show()\n",
        "    \n",
        "    return fig\n",
        "\n",
        "\n",
        "def print_district_summary(stats_history, iteration=None):\n",
        "    \"\"\"Print detailed summary for a specific iteration (default: last).\"\"\"\n",
        "    \n",
        "    if iteration is None:\n",
        "        stats = stats_history[-1]\n",
        "    else:\n",
        "        stats = next((s for s in stats_history if s['iteration'] == iteration), None)\n",
        "        if stats is None:\n",
        "            print(f\"No stats found for iteration {iteration}\")\n",
        "            return\n",
        "    \n",
        "    print(\"=\"*80)\n",
        "    print(f\"DISTRICT SUMMARY - ITERATION {stats['iteration']}\")\n",
        "    print(\"=\"*80)\n",
        "    \n",
        "    print(\"\\nAGGREGATE METRICS:\")\n",
        "    print(f\"  Efficiency Gap: {stats['efficiency_gap']:,}\")\n",
        "    print(f\"  Avg Compactness: {stats['avg_compactness']:.4f}\")\n",
        "    print(f\"  Total Wasted D: {stats['total_wasted_d']:,}\")\n",
        "    print(f\"  Total Wasted R: {stats['total_wasted_r']:,}\")\n",
        "    \n",
        "    # Count Democratic districts\n",
        "    dem_count = sum(1 for dist_stats in stats['district_stats'].values() \n",
        "                   if dist_stats['VoterReg_D'] > dist_stats['VoterReg_R'])\n",
        "    print(f\"  Democratic Districts: {dem_count}/{len(stats['district_stats'])}\")\n",
        "    \n",
        "    print(\"\\nDISTRICT DETAILS:\\n\")\n",
        "    \n",
        "    for dist_id, dist_stats in sorted(stats['district_stats'].items()):\n",
        "        winner = 'D' if dist_stats['VoterReg_D'] > dist_stats['VoterReg_R'] else 'R'\n",
        "        margin = abs(dist_stats['VoterReg_D'] - dist_stats['VoterReg_R'])\n",
        "        \n",
        "        print(f\"  District {dist_id} (Winner: {winner}, Margin: {margin:,}):\")\n",
        "        print(f\"    Population: {dist_stats['population']:,}\")\n",
        "        print(f\"    Compactness: {dist_stats['polsby_popper']:.4f}\")\n",
        "        print(f\"    D Votes: {dist_stats['VoterReg_D']:,} | R Votes: {dist_stats['VoterReg_R']:,}\")\n",
        "        print(f\"    Wasted D: {dist_stats['wasted_D_votes']:,} | Wasted R: {dist_stats['wasted_R_votes']:,}\")\n",
        "        print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRScCEKAvCaO"
      },
      "source": [
        "### Main Execution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        },
        "id": "hui8Ft7pvYHl",
        "outputId": "e0ea312f-bb84-44dc-d5fd-7704afe1f56a"
      },
      "outputs": [],
      "source": [
        "if __name__ == \"__main__\":\n",
        "\n",
        "    # Configuration\n",
        "    NUM_DISTRICTS = 9\n",
        "    POP_TOLERANCE = 0.1  # 10% tolerance\n",
        "    NUM_ITERATIONS = 10000\n",
        "    COMPACTNESS_LOWER_BOUND = 0.15\n",
        "    PARTY_PREFERENCE = 'R'  # 'D', 'R', or None\n",
        "    ACCEPTANCE_RATE = 0.8\n",
        "    NODE_REPEATS = 10  # Number of spanning trees to try during initialization\n",
        "\n",
        "    # Load shapefile\n",
        "    print(\"=\"*60)\n",
        "    print(\"LOADING DATA AND INITIALIZING\")\n",
        "    print(\"=\"*60)\n",
        "    print(\"\\nLoading shapefile...\")\n",
        "    gdf = gpd.read_file('/Data/VTD.shp')\n",
        "\n",
        "    # CRITICAL: Reset index\n",
        "    gdf = gdf.reset_index(drop=True)\n",
        "    print(f\"âœ“ Loaded {len(gdf)} VTDs\")\n",
        "\n",
        "    # Calculate ideal population\n",
        "    total_population = gdf['TOTAL'].sum()\n",
        "    ideal_pop = total_population / NUM_DISTRICTS\n",
        "    print(f\"âœ“ Total population: {total_population:,}\")\n",
        "    print(f\"âœ“ Ideal population per district: {ideal_pop:,.0f}\")\n",
        "\n",
        "    # Build adjacency graph\n",
        "    print(\"\\nBuilding adjacency graph...\")\n",
        "    start_time = time.time()\n",
        "    graph = build_adjacency_graph(gdf)\n",
        "    graph_time = time.time() - start_time\n",
        "    print(f\"âœ“ Built graph with {graph.number_of_nodes()} nodes and {graph.number_of_edges()} edges in {graph_time:.2f}s\")\n",
        "\n",
        "    # Initialize districts using recursive tree partitioning\n",
        "    print(\"\\nInitializing districts with recursive tree partitioning...\")\n",
        "    gdf['district'] = recursive_tree_part_init(gdf, graph, NUM_DISTRICTS, ideal_pop,\n",
        "                                                tolerance=POP_TOLERANCE, node_repeats=NODE_REPEATS)\n",
        "\n",
        "    # Optional: Save initialized map\n",
        "    initialized_path = '/Data/Initial_Map.shp'\n",
        "    gdf.to_file(initialized_path)\n",
        "    print(f\"\\nâœ“ Initialized map saved to: {initialized_path}\")\n",
        "\n",
        "    # Run iterative redistricting\n",
        "    gdf_redistricted, district_stats_new, metrics, stats_history, gdf_snapshots = redistrict_iterative(\n",
        "        gdf=gdf,\n",
        "        graph=graph,  # Pass the pre-built graph\n",
        "        num_iterations=NUM_ITERATIONS,\n",
        "        pop_tolerance=POP_TOLERANCE,\n",
        "        compactness_lower_bound=COMPACTNESS_LOWER_BOUND,\n",
        "        party_preference=PARTY_PREFERENCE,\n",
        "        acceptance_rate=ACCEPTANCE_RATE,\n",
        "        verbose=True\n",
        "    )\n",
        "\n",
        "    # Visualizations\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"GENERATING VISUALIZATIONS\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    selected_iterations = [0, 2000, 4000, 6000, 8000, 10000]\n",
        "    filtered_snapshots = {k: v for k, v in gdf_snapshots.items() if k in selected_iterations}\n",
        "\n",
        "    # Plot evolution\n",
        "    plot_redistricting_evolution(\n",
        "        filtered_snapshots,\n",
        "        stats_history,\n",
        "        figsize=(20, 12),\n",
        "        save_path='redistricting_evolution.png'\n",
        "    )\n",
        "\n",
        "    # Plot metrics over time\n",
        "    plot_metrics_over_time(\n",
        "        stats_history,\n",
        "        figsize=(16, 10),\n",
        "        save_path='metrics_evolution.png'\n",
        "    )\n",
        "\n",
        "    # NEW: Plot rejection reasons\n",
        "    plot_rejection_reasons(\n",
        "        metrics,\n",
        "        figsize=(10, 6),\n",
        "        save_path='rejection_reasons.png'\n",
        "    )\n",
        "\n",
        "    # Print detailed summary for final iteration\n",
        "    print_district_summary(stats_history)\n",
        "\n",
        "    # Print summary for iteration 100\n",
        "    if len([s for s in stats_history if s['iteration'] == 1000]) > 0:\n",
        "        print_district_summary(stats_history, iteration=1000)\n",
        "\n",
        "    # Print summary for iteration 500\n",
        "    if len([s for s in stats_history if s['iteration'] == 5000]) > 0:\n",
        "        print_district_summary(stats_history, iteration=5000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "py311",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
